{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_4차과제_2020250003.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2hv2Zq9SIBejBjiBTYAyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimiswater/ML_5/blob/main/ML_4%EC%B0%A8%EA%B3%BC%EC%A0%9C_2020250003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3mPjv3QWaWj"
      },
      "source": [
        "### **기본설정**\n",
        "#####  \n",
        "\n",
        "*   필수 모듈 불러오기\n",
        "*   그래프 출력 관련 기본 설정하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trKgrogKWMNU"
      },
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"training_linear_models\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "    \n",
        "# 어레이 데이터를 csv 파일로 저장하기\n",
        "def save_data(fileName, arrayName, header=''):\n",
        "    np.savetxt(fileName, arrayName, delimiter=',', header=header, comments='')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIeJ9K2NWyu3"
      },
      "source": [
        "### **🎈 과제 1**\n",
        "##### 조기 종료를 사용한 배치 경사 하강법으로 로지스틱 회귀를 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wUqN7eQWYej"
      },
      "source": [
        "#### **데이터 준비**\n",
        "\n",
        "##### 붓꽃 데이터셋의 꽃잎 길이(petal length)와 꽃잎 너비(petal width) 특성만 이용한다.\n",
        "\n",
        "##### 꽃의 품종이  버지니카인지 아닌지 판별할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrHD2gO2XB0v"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j6KML7RXl7H",
        "outputId": "d911ff40-b21b-4e57-8458-5c7641c05bb0"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvMEZmUiXsam"
      },
      "source": [
        "X = iris[\"data\"][:, (2,3)] # 꽃잎 길이, 꽃잎 넓이\n",
        "y = (iris[\"target\"] == 2).astype(np.int)  #virginica 판단 모델을 위한 데이터셋"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG3UPpsIYHgV"
      },
      "source": [
        "\n",
        "*   0번 특성값 x0이 항상 1이라고 가정하기 때문에 모든 샘플에 편향을 추가한다.\n",
        "\n",
        "   $$ θ0 ⋅ 1 + θ1 ⋅ x1 + ⋯ + θn ⋅ xn = θ0 ⋅ x0 + θ1 ⋅ x1 + ⋯ + θn ⋅ xn $$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmoVw4oAYBde"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKXWh9vdZl42"
      },
      "source": [
        "##### 결과를 일정하게 유지하기 위해 랜덤 시드를 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vpbHhffZgYO"
      },
      "source": [
        "np.random.seed(2042)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1cHZvGeZvmD"
      },
      "source": [
        "#### **데이터 분할**\n",
        "\n",
        "##### 데이터셋을 훈련, 검증, 테스트 용도로 6대 2대 2의 비율로 무작위로 분할한다.\n",
        "\n",
        "\n",
        "*   훈련 세트 : 60%\n",
        "*   검증 세트 : 20%\n",
        "*   테스트 세트 : 20%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzpAFPshaUHP"
      },
      "source": [
        "test_ratio = 0.2                  # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2            # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)     # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)    # 검증 세트 크기 : 전체의 20%\n",
        "train_size = total_size - test_size - validation_size   # 훈련 세트 크기 : 전체의 60%"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs7OQPc5beA9"
      },
      "source": [
        "##### np.random.permutation() 함수를 이용하여 인덱스를 무작위로 섞는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4gi8HJFbghU"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6CweVQzbrmG"
      },
      "source": [
        "*   인덱스가 무작위로 섞였기 때문에 무작위로 분할하는 효과를 얻는다.\n",
        "*   섞인 인덱스를 이용하여 지정된 6:2:2의 비율로 훈련, 검증, 테스트 세트로 분할한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mh-Ye0mbqOO"
      },
      "source": [
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_vaild = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_vaild = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xojBu2WncqX1"
      },
      "source": [
        "#### **타깃 변환**\n",
        "##### 타깃은 0,1,2로 설정되어 있다. 차례대로 세토사, 버시컬러, 버지니카 품종을 가리킨다. 훈련 세트의 첫 5개 샘플의 품종은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-YLdVacp7A",
        "outputId": "c0f16ef5-a26c-4d6d-cc16-9f10d2ec7488"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mQZB3XFdGY1"
      },
      "source": [
        "#### **로시스틱 모델 구현**\n",
        "\n",
        "로지스틱에 사용되는 시그모이드 함수를 만든다.\n",
        "\n",
        "$$\n",
        "\\sigma(t) = \\frac{1}{1 + e^{-t}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1kVB7v_eQu-"
      },
      "source": [
        "def logistic(logits):\n",
        "    return 1.0 / (1 + np.exp(-logits))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LE2qaYzeoNF"
      },
      "source": [
        "##### 가중치를 조정해나가기 위해 세타를 생성하고 초기값은 랜덤이다.\n",
        "\n",
        "##### 여기서 n은 특성이 2개이므로 2가 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83AHyYeDen9b"
      },
      "source": [
        "n_inputs = X_train.shape[1] # 편향과 특성의 개수\n",
        "Theta = np.random.randn(n_inputs) # 편향과 특성의 개수만큼 세타값 랜덤 초기화  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnFxI4VKfOQ1"
      },
      "source": [
        "#### **비용함수 구현**\n",
        "\n",
        "$$\n",
        "J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}\n",
        "$$\n",
        "\n",
        "\n",
        "##### 위의 수식을 코드로 표현하면 다음과 같다.\n",
        "\n",
        "-np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq7bMxovhjjx"
      },
      "source": [
        "##### 배치 경사 하강법 훈련은 아래의 코드를 통해 이루어진다.\n",
        "\n",
        "\n",
        "\n",
        "*   `eta = 0.01` : 학습률\n",
        "*   `n_iterations = 5001` : 에포크 수\n",
        "*   `m = len(X_train)` : 훈련 세트 크기(훈련 샘플 수)\n",
        "*   `epsilon = 1e-7` : $log$값이 항상 계산되도록 더해지는 작은 실수 \n",
        "*   `logits` : 모든 샘플에 대한 클래스별 점수($\\mathbf{X}_{\\textit{train}}\\, \\Theta$)\n",
        "*   `Y_proba` : 모든 샘플에 대해 계산된 클래스 별 소속 확률($\\hat P$)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vix5T994g6AP",
        "outputId": "f40221f8-5829-420e-c4bc-ab51129e5181"
      },
      "source": [
        "# 배치 경사하강법 구현\n",
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "# 5001번 반복 훈련\n",
        "for iteration in range(n_iterations) :\n",
        "    logits = X_train.dot(Theta) # 행렬연산을 이용하여 세타와 x값을 곱한다.\n",
        "    Y_proba = logistic(logits)  # logits 값을 시그모이드 함수에 넣는다.\n",
        "\n",
        "    # 500 에포크마다 손실(비용) 계산해서 출력\n",
        "    if iteration % 500 == 0 :\n",
        "      # 손실함수 계산을 통해 손실비용 loss를 얻는다.\n",
        "      loss = -np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))\n",
        "      print(iteration, loss)\n",
        "\n",
        "    # 그레이디언트 계산\n",
        "    error = Y_proba - y_train # y의 확률값과 실제 y의 값의 차이다.\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "\n",
        "    # 파라미터 업데이트\n",
        "    Theta = Theta - eta * gradients # 세타에 학습률 * gradient의 값을 빼서 세타 값을 재조정한 뒤 다음 에포크로 넘어간다.  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 79.35473984499612\n",
            "500 27.149524631560638\n",
            "1000 21.89438928577945\n",
            "1500 19.33777344771706\n",
            "2000 17.691444239326714\n",
            "2500 16.49516908325313\n",
            "3000 15.566000472955372\n",
            "3500 14.81327398979558\n",
            "4000 14.185530546071131\n",
            "4500 13.65075154805576\n",
            "5000 13.187653637231028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf2mcDjMklOC",
        "outputId": "1d813633-3d52-40ef-a661-31f04f5e7e4c"
      },
      "source": [
        "# 학습된 파라미터\n",
        "Theta"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-10.56492618,   0.53611169,   4.82694082])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi8GIsPpmGRd"
      },
      "source": [
        "#### **검증 세트에 대한 예측과 정확도**\n",
        "\n",
        "*   `logits`, `Y_proba`를 검증 세트인 `X_vaild`를 이용하여 계산한다.\n",
        "*   `Y_proba`값이 0.5 이상이라면 버지니아로, 아니면 버지니아가 아니라고 입력한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP3kyLwQmSNi",
        "outputId": "6371f932-f0b8-4907-b176-9c8b1f66a99b"
      },
      "source": [
        "logits = X_vaild.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.array([])\n",
        "\n",
        "for i in range(len(Y_proba)) :\n",
        "  if Y_proba[i] >= 0.5 :\n",
        "    y_predict = np.append(y_predict, 1)\n",
        "  else:\n",
        "    y_predict = np.append(y_predict, 0) \n",
        "\n",
        "# 정확도 계산\n",
        "accuaracy_score = np.mean(y_predict == y_vaild)\n",
        "accuaracy_score     "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zmuLxkboX04"
      },
      "source": [
        "### **🎈 과제 2**\n",
        "\n",
        "##### 과제 1에서 구현된 로지스틱 회귀 알고리즘에 일대다(OvR) 방식을 적용하여 붓꽃에 대한 다중 클래스 분류 알고리즘을 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다.\n",
        "\n",
        "\n",
        "\n",
        "*   2개의 로지스틱 모델을 사용해야 한다.\n",
        "*   세토사(setosa)인지 아닌지 판단하는 모델과 버지니카(virginica)인지 아닌지 판단하는 모델을 만든 후에, `versicolor`일 확률은 \" `1 - setosa`일 확률 - `virginica`일 확률\"로 계산한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U70goXFoo3I"
      },
      "source": [
        "X = iris[\"data\"][:, (2,3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]\n",
        "y0 = (iris[\"target\"] == 0).astype(np.int) # setosa 판단 모델을 위한 데이터셋\n",
        "y1 = (iris[\"target\"] == 2).astype(np.int) # virginica 판단 모델을 위한 데이터셋"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77pUnWeiqaL1"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]  # 편향 추가"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVinv-lhql5I"
      },
      "source": [
        "np.random.seed(2042)  # 일정한 결과를 위해 랜덤시드 지정"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7SjxBG0q6fD"
      },
      "source": [
        "test_ratio = 0.2                  # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2            # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)     # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)    # 검증 세트 크기 : 전체의 20%\n",
        "train_size = total_size - test_size - validation_size   # 훈련 세트 크기 : 전체의 60%"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwXzQYhCrATD"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size) # 데이터 섞기"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoujUiorIgu"
      },
      "source": [
        "##### 모델 훈련은 각 클래스에 대해 이루어지기 때문에 데이터셋도 개별적으로 준비한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeypAFc8rPF3"
      },
      "source": [
        "X_train = X_with_bias[rnd_indices[:train_size]] \n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "y_train0 = y0[rnd_indices[:train_size]] #setosa에 대한 훈련 세트\n",
        "y_train1 = y1[rnd_indices[:train_size]] #virginica에 대한 훈련 세트\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "y_valid0 = y0[rnd_indices[train_size:-test_size]] #setosa에 대한 검증 세트 \n",
        "y_valid1 = y1[rnd_indices[train_size:-test_size]] #virginica에 대한 검증 세트 \n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ4HNC_groFG"
      },
      "source": [
        "n_inputs = X_train.shape[1]\n",
        "Theta0 = np.random.randn(n_inputs) #setosa 판단모델에 쓰이는 세타 값\n",
        "Theta1 = np.random.randn(n_inputs) #virginica 판단모델에 쓰이는 세타 값"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGx059V6rt4v"
      },
      "source": [
        "##### **세토사(setosa) 판별 로지스틱 회귀 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUT_VplPr3j5",
        "outputId": "c33558cc-9a00-4377-bcf1-0a2628ce2835"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5             # 규제 하이퍼파라미터\n",
        "best_loss0 = np.infty   # 최소 손실 값 기억 변수\n",
        "\n",
        "Theta0 = np.random.randn(n_inputs)  # 파라미터 초기화\n",
        "\n",
        "for iteration in range(n_iterations) :\n",
        "  # 훈련 및 손실 계산\n",
        "  logits0 = X_train.dot(Theta0)\n",
        "  Y_proba0 = logistic(logits0)\n",
        "  error = Y_proba0 - y_train0\n",
        "  gradients0 = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1]), alpha * Theta0[1:]]\n",
        "  Theta0 = Theta0 - eta * gradients0\n",
        "\n",
        "  # 검증 세트에 대한 손실 계산\n",
        "  logits0 = X_vaild.dot(Theta0)\n",
        "  Y_proba0 = logistic(logits0)\n",
        "  xentropy_loss0 = -np.mean(np.sum((y_valid0*np.log(Y_proba0 + epsilon) + (1-y_valid0)*np.log(1 - Y_proba0 + epsilon))))\n",
        "  l2_loss0 = 1/2 * np.sum(np.square(Theta0[1:]))\n",
        "  loss0 = xentropy_loss0 + alpha * l2_loss0\n",
        "\n",
        "  # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "  if iteration % 500 == 0 :\n",
        "    print(iteration, loss0)\n",
        "\n",
        "  # 에포크마다 최소 손실값 업데이트\n",
        "  if loss0 < best_loss0 :\n",
        "    best_loss0 = loss0\n",
        "  else : # 에포크가 줄어들지 않으면\n",
        "     print(iteration - 1, best_loss0) # 종료되기 이전의 에포크의 손실값 출력\n",
        "     print(iteration, loss0, \"조기 종료\")\n",
        "     break   "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 20.540019459712514\n",
            "500 7.744571615343959\n",
            "1000 7.672989036271927\n",
            "1500 7.668592640555666\n",
            "2000 7.668314272027711\n",
            "2500 7.668296612120626\n",
            "3000 7.668295491624586\n",
            "3500 7.668295420530142\n",
            "4000 7.668295416019264\n",
            "4500 7.668295415733049\n",
            "5000 7.668295415714894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWusfrIcv2CN"
      },
      "source": [
        "##### **버지니카(virginica) 판별 로지스틱 회귀 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw_MuyJ2v8FI",
        "outputId": "d142ee91-ca47-4650-cbfb-15d359555cd7"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5            # 규제 하이퍼파라미터\n",
        "best_loss1 = np.infty  # 최소 손실값 기억 변수\n",
        "\n",
        "Theta1 = np.random.randn(n_inputs)  # 파라미터 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits1 = X_train.dot(Theta1)\n",
        "    Y_proba1 = logistic(logits1)\n",
        "    error = Y_proba1 - y_train1\n",
        "    gradients1 = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1]), alpha * Theta1[1:]]\n",
        "    Theta1 = Theta1 - eta * gradients1\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits1 = X_valid.dot(Theta1)\n",
        "    Y_proba1 = logistic(logits1)\n",
        "    xentropy_loss1 = -np.mean(np.sum((y_valid1*np.log(Y_proba1 + epsilon) + (1-y_valid1)*np.log(1 - Y_proba1 + epsilon))))\n",
        "    l2_loss1 = 1/2 * np.sum(np.square(Theta1[1:]))\n",
        "    loss1 = xentropy_loss1 + alpha * l2_loss1\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss1)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss1 < best_loss1:\n",
        "        best_loss1 = loss1\n",
        "    else: # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss1)        # 종료되기 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss1, \"조기 종료\")\n",
        "        break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 45.38818486389959\n",
            "500 12.482904005693054\n",
            "1000 11.947222069327108\n",
            "1500 11.864096195806566\n",
            "2000 11.849273910674974\n",
            "2500 11.846566475123907\n",
            "3000 11.846069764314986\n",
            "3500 11.845978563684064\n",
            "4000 11.845961815948371\n",
            "4500 11.845958740374874\n",
            "5000 11.845958175570198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzjfnOw_wOIN"
      },
      "source": [
        "#### **테스트셋에 적용하기**\n",
        "\n",
        "2개의 세타 값을 이용하여 가장 높은 것을 선택하여 분류한다.\n",
        "\n",
        "\n",
        "*   `세토사(setosa)`일 확률 `(setosa_proba)`\n",
        "*   `버지니카(virginica)`일 확률 `(virginica_proba)`\n",
        "*   `versicolor`일 확률 `(1 - setosa_proba - virginica_proba)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-az85DGwz4m"
      },
      "source": [
        "# 세토사(setosa)에 대한 확률값 추정\n",
        "logits = X_test.dot(Theta0)\n",
        "setosa_proba = logistic(logits)\n",
        "\n",
        "# 버지니카(virginica)에 대한 확률값 추정\n",
        "logists = X_test.dot(Theta1)\n",
        "virginica_proba = logistic(logits)\n",
        "\n",
        "y_predict = np.array([])\n",
        "for i in range(len(Y_proba0)) :\n",
        "  proba_list = [[setosa_proba[i], 0], [1 - setosa_proba[i] - virginica_proba[i], 1], [virginica_proba[i],2]]\n",
        "  # 높은 확률 순서대로 정렬\n",
        "  proba_list.sort(reverse = True)\n",
        "  # 가장 높은 확률을 예측값으로 결정\n",
        "  y_predict = np.append(y_predict, proba_list[0][1])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx5ofMuGySIu",
        "outputId": "2f69348b-80f2-42c3-ed9b-e98c15277caa"
      },
      "source": [
        "accuaracy_score = np.mean(y_predict == y_test)\n",
        "accuaracy_score"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}